{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AnimeBigGAN-tf2hub-fast.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/HighCWu/anime_biggan_toy/blob/main/colab/AnimeBigGAN_tf2hub_fast.ipynb",
      "authorship_tag": "ABX9TyMmjRZHr3WcNU7JGwsOt7C4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HighCWu/anime_biggan_toy/blob/main/colab/AnimeBigGAN_tf2hub_fast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlVZhUmS6XIj"
      },
      "source": [
        "## Download Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtKvvSf16gPI"
      },
      "source": [
        "!rsync --verbose --progress rsync://78.46.86.149:873/biggan/2020-05-18-spresser-biggan-256px-danbooruplus-run39-607250.tar.xz ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5epbEzb46iLl"
      },
      "source": [
        "!tar -xf 2020-05-18-spresser-biggan-256px-danbooruplus-run39-607250.tar.xz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mecgcLj6jhi"
      },
      "source": [
        "!cp 2020-05-18-spresser-biggan-256px-danbooruplus-run39-607250 drive/My\\ Drive/ -r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuKVT_E26bsI"
      },
      "source": [
        "## Restore Model And Convert To TFHUB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "799hweZO5_qV"
      },
      "source": [
        "!pip install mock\n",
        "!git clone https://github.com/HighCWu/compare_gan\n",
        "!cd compare_gan && git checkout easyhub\n",
        "!cd compare_gan && pip install -e .\n",
        "!cp drive/My\\ Drive/2020-05-18-spresser-biggan-256px-danbooruplus-run39-607250 ./compare_gan/ -r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjrDbPjNHS_L"
      },
      "source": [
        "import os\n",
        "os.chdir('compare_gan')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEUkwMqLIMn0"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUJgSBKyDAGy"
      },
      "source": [
        "# ModularGAN extend build_graph fn\n",
        "import tensorflow as tf\n",
        "from compare_gan.gans.modular_gan import ModularGAN\n",
        "\n",
        "\n",
        "def build_graph(self, model=None):\n",
        "    batch_size = None\n",
        "    is_training = False\n",
        "    y_gen, y_disc = None, None\n",
        "    inputs_gen, inputs_disc = {}, {}\n",
        "    outputs_gen, outputs_disc = {}, {}\n",
        "    inputs_gen[\"z\"] = None if model=='disc' else tf.placeholder(\n",
        "        shape=(batch_size, self._z_dim),\n",
        "        dtype=tf.float32,\n",
        "        name=\"z_for_eval\"\n",
        "    )\n",
        "    inputs_disc[\"images\"] = None if model=='gen' else tf.placeholder(\n",
        "        shape=[batch_size] + list(self._dataset.image_shape),\n",
        "        dtype=tf.float32,\n",
        "        name=\"images_for_eval\"\n",
        "    )\n",
        "    if self.conditional:\n",
        "        inputs_gen[\"labels\"] = None if model=='disc' else tf.placeholder(\n",
        "            shape=(batch_size,),\n",
        "            dtype=tf.int32,\n",
        "            name=\"labels_for_gen_eval\"\n",
        "        )\n",
        "        y_gen = None if model=='disc' else self._get_one_hot_labels(inputs_gen[\"labels\"])\n",
        "        inputs_disc[\"labels\"] = None if model=='gen' else tf.placeholder(\n",
        "            shape=(batch_size,),\n",
        "            dtype=tf.int32,\n",
        "            name=\"labels_for_disc_eval\"\n",
        "        )\n",
        "        y_disc = None if model=='gen' else self._get_one_hot_labels(inputs_disc[\"labels\"])\n",
        "    else:\n",
        "      y_gen, y_disc = None, None\n",
        "\n",
        "    outputs_disc[\"prediction\"], _, _ = (None,None,None) if model=='gen' else self.discriminator(\n",
        "        inputs_disc[\"images\"], y=y_disc, is_training=is_training\n",
        "    )\n",
        "\n",
        "    z = inputs_gen[\"z\"]\n",
        "    generated = None if model=='disc' else self.generator(z=z, y=y_gen, is_training=is_training)\n",
        "    if self._g_use_ema and model != 'disc':\n",
        "        g_vars = [var for var in tf.trainable_variables()\n",
        "              if \"generator\" in var.name]\n",
        "        ema = tf.train.ExponentialMovingAverage(decay=self._ema_decay)\n",
        "        # Create the variables that will be loaded from the checkpoint.\n",
        "        ema.apply(g_vars)\n",
        "        def ema_getter(getter, name, *args, **kwargs):\n",
        "            var = getter(name, *args, **kwargs)\n",
        "            ema_var = ema.average(var)\n",
        "            if ema_var is None:\n",
        "                var_names_without_ema = {\"u_var\", \"accu_mean\", \"accu_variance\",\n",
        "                              \"accu_counter\", \"update_accus\"}\n",
        "                if name.split(\"/\")[-1] not in var_names_without_ema:\n",
        "                    print(\"Could not find EMA variable for %s.\", name)\n",
        "                return var\n",
        "            return ema_var\n",
        "        with tf.variable_scope(\"\", values=[z, y_gen], reuse=True, custom_getter=ema_getter):\n",
        "            ema_generated = self.generator(z, y=y_gen, is_training=is_training)\n",
        "            if not is_training:\n",
        "                generated = ema_generated\n",
        "    outputs_gen[\"generated\"] = None if model=='disc' else generated\n",
        "    return {\n",
        "        \"gen\": {\n",
        "            \"inputs\": inputs_gen, \n",
        "            \"outputs\": outputs_gen\n",
        "        },\n",
        "        \"disc\": {\n",
        "            \"inputs\": inputs_disc,\n",
        "            \"outputs\": outputs_disc\n",
        "        }\n",
        "    }\n",
        "ModularGAN.build_graph = build_graph\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UCcxAoSEP6z"
      },
      "source": [
        "import os\n",
        "import gin\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from compare_gan import main, runner_lib, datasets\n",
        "from compare_gan.gans import utils, modular_gan\n",
        "from compare_gan.gans.modular_gan import ModularGAN\n",
        "\n",
        "os.environ[\"NUM_CORES\"] = '8'\n",
        "gin.parse_config_file('example_configs/bigrun40.gin')\n",
        "gin.bind_parameter(\"standardize_batch.use_cross_replica_mean\", False)\n",
        "src_model_path = '2020-05-18-spresser-biggan-256px-danbooruplus-run39-607250/'\n",
        "\n",
        "use_ema = True\n",
        "\n",
        "class FakeDataset:\n",
        "    num_classes = 1000\n",
        "    random_labels = True\n",
        "    image_shape = (256, 256, 3)\n",
        "\n",
        "\n",
        "model = ModularGAN(FakeDataset, {\n",
        "        \"architecture\": \"resnet_biggan_arch\",\n",
        "        \"z_dim\": 140,\n",
        "        \"lambda\": 1,\n",
        "    }, src_model_path, g_use_ema=use_ema\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT1uTikUztUU"
      },
      "source": [
        "import os\n",
        "import itertools\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from compare_gan.architectures import arch_ops\n",
        "arch_ops.use_assign_forbidden = False\n",
        "\n",
        "os.makedirs('accu_samples', exist_ok=True)\n",
        "\n",
        "batch_size = 8\n",
        "num_accu_steps = 8 # a few steps and accu all levels together\n",
        "export_path = os.path.join('anime-biggan-256px-run39-607250', \"tfhub\")\n",
        "checkpoint_path = os.path.join('anime-biggan-256px-run39-607250-tmp', \"model.ckpt\")\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    inout_nodes = model.build_graph()\n",
        "    inout_gen, inout_disc = inout_nodes[\"gen\"], inout_nodes[\"disc\"]\n",
        "    init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
        "    sess.run(init_op)\n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess, src_model_path + 'model.ckpt-607250')\n",
        "    update_accu_switches = [v for v in tf.global_variables()\n",
        "                 if \"accu/update_accus\" in v.name]\n",
        "    def run_model():\n",
        "        z = rng.randn(batch_size, model._z_dim).astype(np.float32)\n",
        "        if not model.conditional:\n",
        "            _z = inout_gen['inputs']['z']\n",
        "            images = sess.run(inout_gen['outputs']['generated'], feed_dict={_z: z})\n",
        "        else:\n",
        "            y = rng.randint(model._dataset.num_classes, size=(batch_size, )).astype(np.int32)\n",
        "            _z = inout_gen['inputs']['z']\n",
        "            _y_gen = inout_gen['inputs']['labels']\n",
        "            images = sess.run(inout_gen['outputs']['generated'], feed_dict={_z: z, _y_gen: y})\n",
        "        return images\n",
        "    for j, update_accu in enumerate(update_accu_switches):\n",
        "        sess.run(tf.assign(update_accu, 1))\n",
        "\n",
        "    rng = np.random.RandomState(0)\n",
        "    for i in range(num_accu_steps):\n",
        "        images = run_model()\n",
        "        dst_filename = f'accu_samples/batchsize_{batch_size}.png'\n",
        "        image = Image.fromarray(np.uint8(images.transpose((1,0,2,3)).reshape((256,-1,3)).clip(0,1) * 255))\n",
        "        image.save(f'accu_samples/batchsize_{batch_size}_accu_{str(i+1).zfill(5)}.png')\n",
        "        print(f'Updating BN accumulators {str(i+1).zfill(5)}/{str(num_accu_steps).zfill(5)} steps.')\n",
        "    \n",
        "    for j, update_accu in enumerate(update_accu_switches):\n",
        "        sess.run(tf.assign(update_accu, 0))\n",
        "    \n",
        "    rng = np.random.RandomState(0)\n",
        "    images = run_model()\n",
        "    dst_filename = f'accu_samples/batchsize_{batch_size}.png'\n",
        "    image = Image.fromarray(np.uint8(images.transpose((1,0,2,3)).reshape((256,-1,3)).clip(0,1) * 255))\n",
        "    image.save(dst_filename)\n",
        "    print('Done updating BN accumulators.')\n",
        "\n",
        "    saver = tf.train.Saver()\n",
        "    saver.save(sess, checkpoint_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPvyB5lRW5Jn"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "from compare_gan.architectures import arch_ops\n",
        "arch_ops.use_assign_forbidden = True\n",
        "\n",
        "def model_fn(model_type):\n",
        "    inout_nodes = model.build_graph(model_type)\n",
        "    inout_gen, inout_disc = inout_nodes[\"gen\"], inout_nodes[\"disc\"]\n",
        "    if model_type == 'gen' or model_type is None:\n",
        "        hub.add_signature(inputs=inout_gen['inputs'], outputs=inout_gen['outputs'])\n",
        "    else:\n",
        "        hub.add_signature(inputs=inout_disc['inputs'], outputs=inout_disc['outputs'])\n",
        "tags_and_args = [\n",
        "    (set(), {\"model_type\": None}),\n",
        "    ({\"gen\", \"bsNone\"}, { \"model_type\": \"gen\" }),\n",
        "    ({\"disc\", \"bsNone\"}, { \"model_type\": \"disc\" })]\n",
        "module_spec = hub.create_module_spec(\n",
        "    model_fn, tags_and_args=tags_and_args,\n",
        "    drop_collections=[tf.GraphKeys.MOVING_AVERAGE_VARIABLES]\n",
        ")\n",
        "\n",
        "module_spec.export(export_path, checkpoint_path=checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxk-ZR34ZVMQ"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "export_path = os.path.join('anime-biggan-256px-run39-607250', \"tfhub\")\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Load module.\n",
        "module = hub.Module(export_path)\n",
        "\n",
        "batch_size = 4\n",
        "z_dim = 140\n",
        "\n",
        "# Sample random noise (z) and ImageNet label (y) inputs.\n",
        "z = tf.random.normal(shape=[batch_size, z_dim],stddev=1.0, seed=0)  # noise sample\n",
        "labels = tf.random.uniform([batch_size], maxval=1000, dtype=tf.int32, seed=0)\n",
        "inputs = dict(z=z, labels=labels)\n",
        "\n",
        "sess = tf.Session()\n",
        "samples = module(inputs, as_dict=True)\n",
        "init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
        "sess.run(init_op)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt4EaoYMVT3r"
      },
      "source": [
        "ret = sess.run(samples)['generated']\n",
        "for it in ret:\n",
        "    display(Image.fromarray(np.uint8(it.clip(0,1)*255)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96Swjf3na0fM"
      },
      "source": [
        "!cp anime-biggan-256px-run39-607250 ../drive/My\\ Drive/ -r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi_lX9ZAMVv3"
      },
      "source": [
        "## Interpolate Exp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bsq95toU_wC"
      },
      "source": [
        "!mkdir data -p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAyf-deXP1Oc"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "export_path = os.path.join('anime-biggan-256px-run39-607250', \"tfhub\")\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Load module.\n",
        "module = hub.Module(export_path)\n",
        "\n",
        "batch_size = None\n",
        "z_dim = 140\n",
        "\n",
        "z = tf.placeholder(shape=[batch_size, z_dim],dtype=tf.float32,name=\"z_for_eval\")\n",
        "labels = tf.placeholder(shape=[batch_size,],dtype=tf.int32,name=\"labels_for_gen_eval\")\n",
        "inputs = dict(z=z, labels=labels)\n",
        "\n",
        "sess = tf.Session()\n",
        "samples = module(inputs, as_dict=True)\n",
        "init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
        "sess.run(init_op)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb_07HW6Mabs"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from sys import stdout\n",
        "\n",
        "class RandomState(object):\n",
        "    rng = None\n",
        "rds = RandomState\n",
        "\n",
        "def std_gen(batch_size=8, seed=None):\n",
        "    if seed is not None:\n",
        "        rds.rng = np.random.RandomState(seed)\n",
        "    elif rds.rng is None:\n",
        "        rds.rng = np.random\n",
        "    x_np = rds.rng.randn(batch_size,140).astype('float32')\n",
        "    y_np = rds.rng.randint(0,1000,size=[batch_size]).astype('int32')\n",
        "    img = sess.run(samples, feed_dict={z: x_np, labels: y_np})['generated']\n",
        "    img = np.uint8(img.clip(0,1)*255)\n",
        "    imgs = []\n",
        "    for i in range(len(img)):\n",
        "        imgs += [Image.fromarray(img[i])]\n",
        "    return imgs\n",
        "\n",
        "def std_gen_interpolate(batch_size=8, seed=None, out_path='data/out.mp4', levels=None, interpolate_mode=0):\n",
        "    default_levels = (\"z0;z1;z2;z3;z4;z5;z6\")\n",
        "    if levels is None:\n",
        "        levels = default_levels\n",
        "    default_levels = default_levels.split(';')\n",
        "\n",
        "    img_save_dir = os.path.join('/tmp', out_path+'.dir')\n",
        "    !rm -rf $img_save_dir\n",
        "    !mkdir $img_save_dir -p\n",
        "    if seed is not None:\n",
        "        rds.rng = np.random.RandomState(seed)\n",
        "    elif rds.rng is None:\n",
        "        rds.rng = np.random\n",
        "    x_np = rds.rng.randn(batch_size,140).astype('float32')\n",
        "    y_np = rds.rng.randint(0,1000,size=[batch_size]).astype('int32')[:1] # use the same class because it's not easy to crack the model inner\n",
        "    x_np = np.concatenate([x_np, x_np[:1]], 0)\n",
        "    levels = levels.split(';')\n",
        "    for level in default_levels:\n",
        "        if len(level) >= 2:\n",
        "            idx = int(level[1])*20\n",
        "            locals()[level] = x_np[:,idx:idx+20]\n",
        "            locals()['_'+level] = x_np[:1,idx:idx+20]\n",
        "    imgs = []\n",
        "    for i in range(batch_size):\n",
        "        for j in range(40):\n",
        "            alpha = j / 40\n",
        "            if interpolate_mode == 1:\n",
        "                alpha = alpha**2 * (3 - 2 * alpha)\n",
        "            for level in levels:\n",
        "                locals()['_'+level] = (1 - alpha) *  locals()[level][i:i+1] + alpha * locals()[level][i+1:i+2]\n",
        "            inputs = []\n",
        "            for level in default_levels:\n",
        "                inputs.append(locals()['_'+level])\n",
        "            inputs = np.concatenate(inputs, 1)\n",
        "            img = sess.run(samples, feed_dict={z: inputs, labels: y_np})['generated']\n",
        "            img = np.uint8(img.clip(0,1)*255)[0]\n",
        "            imgs.append(Image.fromarray(img))\n",
        "            stdout.write(f'{i*40+j+1}/{40*batch_size}\\r')\n",
        "            stdout.flush()\n",
        "    print('')\n",
        "    for i, img in enumerate(imgs):\n",
        "        img.save(os.path.join(img_save_dir, str(i).zfill(5)+'.png'))\n",
        "    imgs[0].save(out_path+'.gif', save_all=True, append_images=imgs[1:], duration=40, loop=0)\n",
        "    out_path = out_path + '.mp4'\n",
        "    os.system(f'ffmpeg -r 40 -i {img_save_dir}/%05d.png -hide_banner -loglevel warning -nostats -c:v libx264 -crf 23 -y {out_path}')\n",
        "    os.system(f'rm -rf {img_save_dir}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul7dXVghUVqB"
      },
      "source": [
        "# 运行模型的标准生成输出过程 Run Output Process of Model's Standard Generation \n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "def concat_imgs_bsz8(imgs):\n",
        "    np_imgs = [np.asarray(img) for img in imgs]\n",
        "    img1 = np.concatenate(np_imgs[:4], 1)\n",
        "    img2 = np.concatenate(np_imgs[4:], 1)\n",
        "    img = Image.fromarray(np.concatenate([img1, img2], 0))\n",
        "    return img.resize([img.size[0]//2, img.size[1]//2])\n",
        "\n",
        "imgs = std_gen(8, seed=233)\n",
        "for i, img in enumerate(imgs):\n",
        "    img.save(f'data/std_seed233_{str(i).zfill(3)}.png')\n",
        "display(concat_imgs_bsz8(imgs))\n",
        "\n",
        "imgs = std_gen(8, seed=None)\n",
        "for i, img in enumerate(imgs):\n",
        "    img.save(f'data/std_seed233_{str(i+8).zfill(3)}.png')\n",
        "display(concat_imgs_bsz8(imgs))\n",
        "\n",
        "imgs = std_gen(8, seed=234) # 不同的seed不同的结果 Different seed with different result\n",
        "for i, img in enumerate(imgs):\n",
        "    img.save(f'data/std_seed234_{str(i).zfill(3)}.png')\n",
        "display(concat_imgs_bsz8(imgs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWQytehhVY5x"
      },
      "source": [
        "# 运行模型的标准生成动图输出过程 Run Gif Output Process of Model's Standard Generation \n",
        "from IPython.display import display, HTML\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "def display_mp4(path):\n",
        "    print(f'Read from {path}')\n",
        "    from base64 import b64encode\n",
        "    mp4 = open(path,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    display(HTML(\"\"\"\n",
        "    <video controls loop autoplay>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\" % data_url))\n",
        "    print('Display finished.')\n",
        "\n",
        "std_gen_interpolate(8, seed=233, out_path='data/std_out1', interpolate_mode=1)\n",
        "std_gen_interpolate(8, seed=None, out_path='data/std_out2', interpolate_mode=0)\n",
        "std_gen_interpolate(8, seed=234, out_path='data/std_out3', interpolate_mode=1) # 不同的seed不同的结果 Different seed with different result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-PFqMiJk_08"
      },
      "source": [
        "# display(HTML('<img src=\"data/std_out1.gif\">'))\n",
        "# display(HTML('<img src=\"data/std_out2.gif\">'))\n",
        "# display(HTML('<img src=\"data/std_out3.gif\">'))\n",
        "\n",
        "# display_mp4(\"data/std_out1.mp4\")\n",
        "display_mp4(\"data/std_out2.mp4\")\n",
        "# display_mp4(\"data/std_out3.mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ucZX4KBlCVI"
      },
      "source": [
        "# 运行模型的标准生成分层插值动图输出过程 Run Gif Output Process of Model's Standard Generation \n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def display_mp4(path):\n",
        "    print(f'Read from {path}')\n",
        "    from base64 import b64encode\n",
        "    mp4 = open(path,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    display(HTML(\"\"\"\n",
        "    <video controls loop autoplay>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\" % data_url))\n",
        "    print('Display finished.')\n",
        "\n",
        "std_gen_interpolate(8, seed=2333, out_path='data/std_inter1', levels=\"z1\")\n",
        "std_gen_interpolate(8, seed=2333, out_path='data/std_inter2', levels=\"z2\")\n",
        "std_gen_interpolate(8, seed=2333, out_path='data/std_inter3', levels=\"z3\")\n",
        "std_gen_interpolate(8, seed=2333, out_path='data/std_inter4', levels=\"z4\")\n",
        "std_gen_interpolate(8, seed=2333, out_path='data/std_inter5', levels=\"z5\")\n",
        "std_gen_interpolate(8, seed=2333, out_path='data/std_inter6', levels=\"z6\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymeq93nOlFuY"
      },
      "source": [
        "# display(HTML('<img src=\"data/std_inter1.gif\">'))\n",
        "# display(HTML('<img src=\"data/std_inter2.gif\">'))\n",
        "# display(HTML('<img src=\"data/std_inter3.gif\">'))\n",
        "# display(HTML('<img src=\"data/std_inter4.gif\">'))\n",
        "# display(HTML('<img src=\"data/std_inter5.gif\">'))\n",
        "# display(HTML('<img src=\"data/std_inter6.gif\">'))\n",
        "\n",
        "# display_mp4(\"data/std_inter1.mp4\")\n",
        "# display_mp4(\"data/std_inter2.mp4\")\n",
        "# display_mp4(\"data/std_inter3.mp4\")\n",
        "display_mp4(\"data/std_inter4.mp4\")\n",
        "# display_mp4(\"data/std_inter5.mp4\")\n",
        "# display_mp4(\"data/std_inter6.mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}