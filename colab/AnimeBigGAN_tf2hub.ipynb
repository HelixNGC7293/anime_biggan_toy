{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AnimeBigGAN-tf2hub.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1tqTN3glBXCnZLmJ3ZeE9Zxp3o3-W6ByQ",
      "authorship_tag": "ABX9TyN7tIEIlfppcjXl7+GM377T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HighCWu/anime_biggan_toy/blob/main/colab/AnimeBigGAN_tf2hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlVZhUmS6XIj"
      },
      "source": [
        "## Download Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtKvvSf16gPI"
      },
      "source": [
        "!rsync --verbose --progress rsync://78.46.86.149:873/biggan/2020-05-18-spresser-biggan-256px-danbooruplus-run39-607250.tar.xz ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5epbEzb46iLl"
      },
      "source": [
        "!tar -xf 2020-05-18-spresser-biggan-256px-danbooruplus-run39-607250.tar.xz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mecgcLj6jhi"
      },
      "source": [
        "!cp 2020-05-18-spresser-biggan-256px-danbooruplus-run39-607250 drive/My\\ Drive/ -r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuKVT_E26bsI"
      },
      "source": [
        "## Restore Model And Convert To TFHUB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "799hweZO5_qV"
      },
      "source": [
        "!pip install mock\n",
        "!git clone https://github.com/HighCWu/compare_gan\n",
        "!cd compare_gan && git checkout easyhub\n",
        "!cd compare_gan && pip install -e .\n",
        "!cp drive/My\\ Drive/2020-05-18-spresser-biggan-256px-danbooruplus-run39-607250 ./compare_gan/ -r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjrDbPjNHS_L"
      },
      "source": [
        "import os\n",
        "os.chdir('compare_gan')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEUkwMqLIMn0"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUJgSBKyDAGy"
      },
      "source": [
        "# ModularGAN extend build_graph fn\n",
        "import tensorflow as tf\n",
        "from compare_gan.gans.modular_gan import ModularGAN\n",
        "\n",
        "\n",
        "def build_graph(self, model=None):\n",
        "    batch_size = None\n",
        "    is_training = False\n",
        "    y_gen, y_disc = None, None\n",
        "    inputs_gen, inputs_disc = {}, {}\n",
        "    outputs_gen, outputs_disc = {}, {}\n",
        "    inputs_gen[\"z\"] = None if model=='disc' else tf.placeholder(\n",
        "        shape=(batch_size, self._z_dim),\n",
        "        dtype=tf.float32,\n",
        "        name=\"z_for_eval\"\n",
        "    )\n",
        "    inputs_disc[\"images\"] = None if model=='gen' else tf.placeholder(\n",
        "        shape=[batch_size] + list(self._dataset.image_shape),\n",
        "        dtype=tf.float32,\n",
        "        name=\"images_for_eval\"\n",
        "    )\n",
        "    if self.conditional:\n",
        "        inputs_gen[\"labels\"] = None if model=='disc' else tf.placeholder(\n",
        "            shape=(batch_size,),\n",
        "            dtype=tf.int32,\n",
        "            name=\"labels_for_gen_eval\"\n",
        "        )\n",
        "        y_gen = None if model=='disc' else self._get_one_hot_labels(inputs_gen[\"labels\"])\n",
        "        inputs_disc[\"labels\"] = None if model=='gen' else tf.placeholder(\n",
        "            shape=(batch_size,),\n",
        "            dtype=tf.int32,\n",
        "            name=\"labels_for_disc_eval\"\n",
        "        )\n",
        "        y_disc = None if model=='gen' else self._get_one_hot_labels(inputs_disc[\"labels\"])\n",
        "    else:\n",
        "      y_gen, y_disc = None, None\n",
        "\n",
        "    outputs_disc[\"prediction\"], _, _ = (None,None,None) if model=='gen' else self.discriminator(\n",
        "        inputs_disc[\"images\"], y=y_disc, is_training=is_training\n",
        "    )\n",
        "    # if model!='gen':\n",
        "    #     for tensor in [tensor for op in tf.get_default_graph().get_operations() for tensor in op.values()]:\n",
        "    #         if outputs_disc[\"prediction\"].name.split('/')[0] in tensor.name and \\\n",
        "    #             'B7/same_conv2/add:0' in tensor.name:\n",
        "    #             outputs_disc[\"features\"] = tensor\n",
        "    #             print('Output Tensors:', outputs_disc)\n",
        "    #             break\n",
        "\n",
        "    z = inputs_gen[\"z\"]\n",
        "    generated = None if model=='disc' else self.generator(z=z, y=y_gen, is_training=is_training)\n",
        "    if self._g_use_ema and model != 'disc':\n",
        "        g_vars = [var for var in tf.trainable_variables()\n",
        "              if \"generator\" in var.name]\n",
        "        ema = tf.train.ExponentialMovingAverage(decay=self._ema_decay)\n",
        "        # Create the variables that will be loaded from the checkpoint.\n",
        "        ema.apply(g_vars)\n",
        "        def ema_getter(getter, name, *args, **kwargs):\n",
        "            var = getter(name, *args, **kwargs)\n",
        "            ema_var = ema.average(var)\n",
        "            if ema_var is None:\n",
        "                var_names_without_ema = {\"u_var\", \"accu_mean\", \"accu_variance\",\n",
        "                              \"accu_counter\", \"update_accus\"}\n",
        "                if name.split(\"/\")[-1] not in var_names_without_ema:\n",
        "                    print(\"Could not find EMA variable for %s.\", name)\n",
        "                return var\n",
        "            return ema_var\n",
        "        with tf.variable_scope(\"\", values=[z, y_gen], reuse=True, custom_getter=ema_getter):\n",
        "            ema_generated = self.generator(z, y=y_gen, is_training=is_training)\n",
        "            if not is_training:\n",
        "                generated = ema_generated\n",
        "    outputs_gen[\"generated\"] = None if model=='disc' else generated\n",
        "    return {\n",
        "        \"gen\": {\n",
        "            \"inputs\": inputs_gen, \n",
        "            \"outputs\": outputs_gen\n",
        "        },\n",
        "        \"disc\": {\n",
        "            \"inputs\": inputs_disc,\n",
        "            \"outputs\": outputs_disc\n",
        "        }\n",
        "    }\n",
        "ModularGAN.build_graph = build_graph\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UCcxAoSEP6z"
      },
      "source": [
        "import os\n",
        "import gin\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from compare_gan import main, runner_lib, datasets\n",
        "from compare_gan.gans import utils, modular_gan\n",
        "from compare_gan.gans.modular_gan import ModularGAN\n",
        "\n",
        "os.environ[\"NUM_CORES\"] = '8'\n",
        "gin.parse_config_file('example_configs/bigrun40.gin')\n",
        "gin.bind_parameter(\"standardize_batch.use_cross_replica_mean\", False)\n",
        "src_model_path = '2020-05-18-spresser-biggan-256px-danbooruplus-run39-607250/'\n",
        "\n",
        "use_ema = True\n",
        "\n",
        "class FakeDataset:\n",
        "    num_classes = 1000\n",
        "    random_labels = True\n",
        "    image_shape = (256, 256, 3)\n",
        "\n",
        "\n",
        "model = ModularGAN(FakeDataset, {\n",
        "        \"architecture\": \"resnet_biggan_arch\",\n",
        "        \"z_dim\": 140,\n",
        "        \"lambda\": 1,\n",
        "    }, src_model_path, g_use_ema=use_ema\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT1uTikUztUU"
      },
      "source": [
        "import os\n",
        "import itertools\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from compare_gan.architectures import arch_ops\n",
        "arch_ops.use_assign_forbidden = False\n",
        "\n",
        "os.makedirs('accu_samples', exist_ok=True)\n",
        "\n",
        "batch_size = 4\n",
        "num_accu_steps = 16384 # In fact, smaller batch size can produce similar results, like 256\n",
        "export_path = os.path.join('anime-biggan-256px-run39-607250', \"tfhub\")\n",
        "checkpoint_path = os.path.join('anime-biggan-256px-run39-607250-tmp', \"model.ckpt\")\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    inout_nodes = model.build_graph()\n",
        "    inout_gen, inout_disc = inout_nodes[\"gen\"], inout_nodes[\"disc\"]\n",
        "    init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
        "    sess.run(init_op)\n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess, src_model_path + 'model.ckpt-607250')\n",
        "    update_accu_switches = [v for v in tf.global_variables()\n",
        "                 if \"accu/update_accus\" in v.name]\n",
        "    def run_model():\n",
        "        z = rng.randn(batch_size, model._z_dim).astype(np.float32)\n",
        "        if not model.conditional:\n",
        "            _z = inout_gen['inputs']['z']\n",
        "            images = sess.run(inout_gen['outputs']['generated'], feed_dict={_z: z})\n",
        "        else:\n",
        "            y = rng.randint(model._dataset.num_classes, size=(batch_size, )).astype(np.int32)\n",
        "            _z = inout_gen['inputs']['z']\n",
        "            _y_gen = inout_gen['inputs']['labels']\n",
        "            images = sess.run(inout_gen['outputs']['generated'], feed_dict={_z: z, _y_gen: y})\n",
        "        return images\n",
        "    for j, update_accu in enumerate(update_accu_switches):\n",
        "        sess.run(tf.assign(update_accu, 1))\n",
        "        rng = np.random.RandomState(0)\n",
        "        for i in range(num_accu_steps):\n",
        "            mean_name = update_accu.name.replace(\"update_accus:0\", \"truediv:0\")\n",
        "            var_name = update_accu.name.replace(\"update_accus:0\", \"truediv_1:0\")\n",
        "            if use_ema:\n",
        "                mean_name = mean_name.replace(\"generator/\", \"generator_1/\")\n",
        "                var_name = var_name.replace(\"generator/\", \"generator_1/\")\n",
        "            mean_tensor = tf.get_default_graph().get_tensor_by_name(mean_name)\n",
        "            var_tensor = tf.get_default_graph().get_tensor_by_name(var_name)\n",
        "            z = rng.randn(batch_size, model._z_dim).astype(np.float32)\n",
        "            if not model.conditional:\n",
        "                _z = inout_gen['inputs']['z']\n",
        "                images = sess.run([mean_tensor, var_tensor], feed_dict={_z: z})\n",
        "            else:\n",
        "                y = rng.randint(model._dataset.num_classes, size=(batch_size, )).astype(np.int32)\n",
        "                _z = inout_gen['inputs']['z']\n",
        "                _y_gen = inout_gen['inputs']['labels']\n",
        "                images = sess.run([mean_tensor, var_tensor], feed_dict={_z: z, _y_gen: y})\n",
        "            if i % 250 == 0:\n",
        "                print(f'Updating BN accumulators {str(i+1).zfill(5)}/{str(num_accu_steps).zfill(5)} steps and {j+1}/{len(update_accu_switches)} levels.')\n",
        "        sess.run(tf.assign(update_accu, 0))\n",
        "    \n",
        "    rng = np.random.RandomState(0)\n",
        "    images = run_model()\n",
        "    dst_filename = f'accu_samples/batchsize_{batch_size}.png'\n",
        "    image = Image.fromarray(np.uint8(images.transpose((1,0,2,3)).reshape((256,-1,3)).clip(0,1) * 255))\n",
        "    image.save(dst_filename)\n",
        "    print('Done updating BN accumulators.')\n",
        "\n",
        "    saver = tf.train.Saver()\n",
        "    saver.save(sess, checkpoint_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPvyB5lRW5Jn"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "from compare_gan.architectures import arch_ops\n",
        "arch_ops.use_assign_forbidden = True\n",
        "\n",
        "def model_fn(model_type):\n",
        "    inout_nodes = model.build_graph(model_type)\n",
        "    inout_gen, inout_disc = inout_nodes[\"gen\"], inout_nodes[\"disc\"]\n",
        "    if model_type == 'gen' or model_type is None:\n",
        "        hub.add_signature(inputs=inout_gen['inputs'], outputs=inout_gen['outputs'])\n",
        "    else:\n",
        "        hub.add_signature(inputs=inout_disc['inputs'], outputs=inout_disc['outputs'])\n",
        "tags_and_args = [\n",
        "    (set(), {\"model_type\": None}),\n",
        "    ({\"gen\", \"bsNone\"}, { \"model_type\": \"gen\" }),\n",
        "    ({\"disc\", \"bsNone\"}, { \"model_type\": \"disc\" })]\n",
        "module_spec = hub.create_module_spec(\n",
        "    model_fn, tags_and_args=tags_and_args,\n",
        "    drop_collections=[tf.GraphKeys.MOVING_AVERAGE_VARIABLES]\n",
        ")\n",
        "\n",
        "module_spec.export(export_path, checkpoint_path=checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxk-ZR34ZVMQ"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "export_path = os.path.join('anime-biggan-256px-run39-607250', \"tfhub\")\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Load module.\n",
        "module = hub.Module(export_path)\n",
        "\n",
        "batch_size = 4\n",
        "z_dim = 140\n",
        "\n",
        "# Sample random noise (z) and ImageNet label (y) inputs.\n",
        "z = tf.random.normal(shape=[batch_size, z_dim],stddev=1.0, seed=0)  # noise sample\n",
        "labels = tf.random.uniform([batch_size], maxval=1000, dtype=tf.int32, seed=0)\n",
        "inputs = dict(z=z, labels=labels)\n",
        "\n",
        "sess = tf.Session()\n",
        "samples = module(inputs, as_dict=True)\n",
        "init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
        "sess.run(init_op)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt4EaoYMVT3r"
      },
      "source": [
        "ret = sess.run(samples)['generated']\n",
        "for it in ret:\n",
        "    display(Image.fromarray(np.uint8(it.clip(0,1)*255)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zru4KOKAZy1L"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    vars = tf.all_variables()\n",
        "    vars_vals = sess.run(vars)\n",
        "\n",
        "    for var, val in zip(vars, vars_vals):\n",
        "        print(var.name, val.shape)  # Prints the name of the variable alongside its value."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96Swjf3na0fM"
      },
      "source": [
        "!cp anime-biggan-256px-run39-607250 ../drive/My\\ Drive/ -r"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}